{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0daf7ba-fcce-4818-9c0a-e8dc98148709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /opt/anaconda3/lib/python3.12/site-packages (19.0.0)\n"
     ]
    }
   ],
   "source": [
    "#Instalar pyarrow\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b7fee0-2406-410c-a8e8-ce04865ff3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f892b0-dab0-491a-b39c-6b8ac0c377a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/anaconda3/lib/python3.12/site-packages (4.3.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (2.0.39)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "113d05d9-0d68-4725-9f2d-08cf3e4fa9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/anaconda3/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe8ea1-7210-4948-902a-46814c0cdba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANIOCAMPANAPROCESO</th>\n",
       "      <th>ANIOCAMPANA</th>\n",
       "      <th>CODEBELISTA</th>\n",
       "      <th>CODTERRITORIO</th>\n",
       "      <th>CODCOMPORTAMIENTOROLLING</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>FLAGCORREOVALIDADO</th>\n",
       "      <th>FLAGCELULAR</th>\n",
       "      <th>FLAGDIGITAL</th>\n",
       "      <th>DESESTADOCIVIL_CAT</th>\n",
       "      <th>...</th>\n",
       "      <th>DESVIACION_REMESA</th>\n",
       "      <th>FLAGNUEVA</th>\n",
       "      <th>FLAG18</th>\n",
       "      <th>FLAG19</th>\n",
       "      <th>FLAG20</th>\n",
       "      <th>DESV_PEDMIN</th>\n",
       "      <th>DESV_PEDMIN_ADJ</th>\n",
       "      <th>CLASE</th>\n",
       "      <th>TARGET_COBRANZA31_CA</th>\n",
       "      <th>PROM_DIAS_PAGO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202414</td>\n",
       "      <td>202410</td>\n",
       "      <td>052370302</td>\n",
       "      <td>57947</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>224.06000</td>\n",
       "      <td>224.06000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>189.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202414</td>\n",
       "      <td>202410</td>\n",
       "      <td>049033176</td>\n",
       "      <td>7361</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.86000</td>\n",
       "      <td>15.86000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>189.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202414</td>\n",
       "      <td>202410</td>\n",
       "      <td>052453461</td>\n",
       "      <td>5033</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>374.16000</td>\n",
       "      <td>374.16000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>189.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202414</td>\n",
       "      <td>202410</td>\n",
       "      <td>052363101</td>\n",
       "      <td>32437</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.76000</td>\n",
       "      <td>51.76000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>189.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202414</td>\n",
       "      <td>202410</td>\n",
       "      <td>052416760</td>\n",
       "      <td>27765</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.67000</td>\n",
       "      <td>67.67000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>189.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ANIOCAMPANAPROCESO ANIOCAMPANA CODEBELISTA CODTERRITORIO  \\\n",
       "0             202414      202410   052370302         57947   \n",
       "1             202414      202410   049033176          7361   \n",
       "2             202414      202410   052453461          5033   \n",
       "3             202414      202410   052363101         32437   \n",
       "4             202414      202410   052416760         27765   \n",
       "\n",
       "  CODCOMPORTAMIENTOROLLING EDAD FLAGCORREOVALIDADO FLAGCELULAR FLAGDIGITAL  \\\n",
       "0                        1   43                  0           1           0   \n",
       "1                        1   31                  0           1           0   \n",
       "2                        1   27                  0           1           0   \n",
       "3                        1   71                  0           1           0   \n",
       "4                        1   29                  0           1           0   \n",
       "\n",
       "  DESESTADOCIVIL_CAT  ... DESVIACION_REMESA FLAGNUEVA FLAG18 FLAG19 FLAG20  \\\n",
       "0                  5  ...           0.00000         1      0      0      0   \n",
       "1                  5  ...           0.00000         1      0      0      0   \n",
       "2                  5  ...           0.00000         1      0      0      0   \n",
       "3                  5  ...           0.00000         1      0      0      0   \n",
       "4                  5  ...           0.00000         1      0      0      0   \n",
       "\n",
       "  DESV_PEDMIN DESV_PEDMIN_ADJ CLASE TARGET_COBRANZA31_CA PROM_DIAS_PAGO  \n",
       "0   224.06000       224.06000     1                    1      189.00000  \n",
       "1    15.86000        15.86000     0                    1      189.00000  \n",
       "2   374.16000       374.16000     1                    1      189.00000  \n",
       "3    51.76000        51.76000     1                    1      189.00000  \n",
       "4    67.67000        67.67000     1                    1      189.00000  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo Parquet\n",
    "df = pd.read_parquet(\"data_input.parquet\")\n",
    "\n",
    "# Visualizar las primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed512ef5-ba0c-48be-8b42-b5812ed17ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951a5252-067b-4fb7-8f32-a513146b23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ebb41a-5c4a-4f85-84cc-74176655bbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones: (99172, 87)\n",
      "\n",
      " Columnas:\n",
      " Index(['ANIOCAMPANAPROCESO', 'ANIOCAMPANA', 'CODEBELISTA', 'CODTERRITORIO',\n",
      "       'CODCOMPORTAMIENTOROLLING', 'EDAD', 'FLAGCORREOVALIDADO', 'FLAGCELULAR',\n",
      "       'FLAGDIGITAL', 'DESESTADOCIVIL_CAT', 'NRO_PEDIDOS', 'NRO_PEDIDOS_U6C',\n",
      "       'NRO_PEDIDOS_U18C', 'CANALINGRESO_CAT', 'REALVTAMNFACTURA', 'CODZONA_X',\n",
      "       'CODREGION', 'EDADBINS', 'PROMEDIOFACTURAS', 'MAXFACTURA', 'MINFACTURA',\n",
      "       'RATIOFACTURAS', 'REGLA_REVISTA', 'REGLA_CATALOGO', 'REGLA_WEB',\n",
      "       'REGLA_OTROS', 'LBEL', 'ESIKA', 'CYZONE', 'ANIOCAMPANAINGRESO',\n",
      "       'GANANCIA_TOTAL', 'DIA_VENC', 'FLAGQUINCENA', 'FLAGINIFIN',\n",
      "       'ANTIGUEDAD', 'FRAGANCIAS', 'CORPORAL', 'FACIAL', 'PERSONAL',\n",
      "       'CAMPANAINGRESO', 'DESNIVELSOCIA', 'DESRENDIMIENTOSOCIA',\n",
      "       'TOTAL_FACTURAS', 'FACTURAS_DEUDA_21_CA', 'FACTURAS_DEUDA_22_CA',\n",
      "       'FACTURAS_DEUDA_23_CA', 'FACTURAS_DEUDA_24_CA', 'FACTURAS_DEUDA_25_CA',\n",
      "       'FACTURAS_DEUDA_26_CA', 'FACTURAS_DEUDA_31_CA', 'FACTURAS_DEUDA_42',\n",
      "       'FACTURAS_DEUDA_63', 'FACTURAS_DEUDA_189', 'RATIO21_CA', 'RATIO22_CA',\n",
      "       'RATIO23_CA', 'RATIO24_CA', 'RATIO25_CA', 'RATIO26_CA', 'RATIO31_CA',\n",
      "       'RATIO42', 'RATIO63', 'RATIO189', 'RATIO999', 'PCTJE_DEUDA_31_CA',\n",
      "       'PCTJE_DEUDA_42', 'PCTJE_DEUDA_63', 'PCTJE_DEUDA_189',\n",
      "       'ULT_CAMPANA_MOROSA', 'COBRABILIDAD21_ZONA', 'COBRABILIDAD26_ZONA',\n",
      "       'COBRABILIDAD31_ZONA', 'COBRABILIDAD189_ZONA', 'REMESA', 'REMESA_H',\n",
      "       'DESVIACION_MAXFACTURA', 'DESVIACION_MINFACTURA', 'DESVIACION_REMESA',\n",
      "       'FLAGNUEVA', 'FLAG18', 'FLAG19', 'FLAG20', 'DESV_PEDMIN',\n",
      "       'DESV_PEDMIN_ADJ', 'CLASE', 'TARGET_COBRANZA31_CA', 'PROM_DIAS_PAGO'],\n",
      "      dtype='object')\n",
      "\n",
      " Tipos de datos:\n",
      " ANIOCAMPANAPROCESO          object\n",
      "ANIOCAMPANA                 object\n",
      "CODEBELISTA                 object\n",
      "CODTERRITORIO               object\n",
      "CODCOMPORTAMIENTOROLLING    object\n",
      "                             ...  \n",
      "DESV_PEDMIN                 object\n",
      "DESV_PEDMIN_ADJ             object\n",
      "CLASE                       object\n",
      "TARGET_COBRANZA31_CA        object\n",
      "PROM_DIAS_PAGO              object\n",
      "Length: 87, dtype: object\n",
      "\n",
      " Valores nulos:\n",
      " ANIOCAMPANAPROCESO          0\n",
      "ANIOCAMPANA                 0\n",
      "CODEBELISTA                 0\n",
      "CODTERRITORIO               0\n",
      "CODCOMPORTAMIENTOROLLING    0\n",
      "                           ..\n",
      "DESV_PEDMIN                 0\n",
      "DESV_PEDMIN_ADJ             0\n",
      "CLASE                       0\n",
      "TARGET_COBRANZA31_CA        0\n",
      "PROM_DIAS_PAGO              0\n",
      "Length: 87, dtype: int64\n",
      "\n",
      " Primeras filas:\n",
      "   ANIOCAMPANAPROCESO ANIOCAMPANA CODEBELISTA CODTERRITORIO  \\\n",
      "0             202414      202410   052370302         57947   \n",
      "1             202414      202410   049033176          7361   \n",
      "2             202414      202410   052453461          5033   \n",
      "3             202414      202410   052363101         32437   \n",
      "4             202414      202410   052416760         27765   \n",
      "\n",
      "  CODCOMPORTAMIENTOROLLING EDAD FLAGCORREOVALIDADO FLAGCELULAR FLAGDIGITAL  \\\n",
      "0                        1   43                  0           1           0   \n",
      "1                        1   31                  0           1           0   \n",
      "2                        1   27                  0           1           0   \n",
      "3                        1   71                  0           1           0   \n",
      "4                        1   29                  0           1           0   \n",
      "\n",
      "  DESESTADOCIVIL_CAT  ... DESVIACION_REMESA FLAGNUEVA FLAG18 FLAG19 FLAG20  \\\n",
      "0                  5  ...           0.00000         1      0      0      0   \n",
      "1                  5  ...           0.00000         1      0      0      0   \n",
      "2                  5  ...           0.00000         1      0      0      0   \n",
      "3                  5  ...           0.00000         1      0      0      0   \n",
      "4                  5  ...           0.00000         1      0      0      0   \n",
      "\n",
      "  DESV_PEDMIN DESV_PEDMIN_ADJ CLASE TARGET_COBRANZA31_CA PROM_DIAS_PAGO  \n",
      "0   224.06000       224.06000     1                    1      189.00000  \n",
      "1    15.86000        15.86000     0                    1      189.00000  \n",
      "2   374.16000       374.16000     1                    1      189.00000  \n",
      "3    51.76000        51.76000     1                    1      189.00000  \n",
      "4    67.67000        67.67000     1                    1      189.00000  \n",
      "\n",
      "[5 rows x 87 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensiones:\", df.shape)\n",
    "print(\"\\n Columnas:\\n\", df.columns)\n",
    "print(\"\\n Tipos de datos:\\n\", df.dtypes)\n",
    "print(\"\\n Valores nulos:\\n\", df.isnull().sum())\n",
    "print(\"\\n Primeras filas:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2df68c-5b81-468a-a653-2d2b95055c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calcular nulos\n",
    "null_counts = df.isnull().sum()\n",
    "null_counts = null_counts[null_counts > 0].sort_values(ascending=False)\n",
    "\n",
    "# Gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=null_counts.values, y=null_counts.index, palette=\"viridis\")\n",
    "plt.title(\"Cantidad de valores nulos por columna\")\n",
    "plt.xlabel(\"N° de valores nulos\")\n",
    "plt.ylabel(\"Columnas\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24ef1d6b-2718-41eb-b99e-fdda977f8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir nombres de columnas a minúsculas\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8997ff6-3482-402d-8f5a-17ced2344aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clase\n",
       "0    0.761778\n",
       "1    0.238222\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balance de la categoría Y\n",
    "df['clase'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9564b753-b45b-4972-8fa7-a07d551e503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Preprocesamiento\n",
    "# ========================\n",
    "\n",
    "# Filtro específico\n",
    "dataset = df[df.target_cobranza31_ca == 1]\n",
    "\n",
    "# Reemplazo y conversión de tipos\n",
    "dataset = dataset.fillna(0)\n",
    "dataset.codzona_x = dataset.codzona_x.replace(\"\", -1)\n",
    "dataset.codregion = dataset.codregion.replace(\"\", -1)\n",
    "dataset.codterritorio = dataset.codterritorio.astype(int)\n",
    "dataset.codzona_x = dataset.codzona_x.astype(int)\n",
    "dataset.codregion = dataset.codregion.astype(int)\n",
    "dataset.aniocampanaingreso = dataset.aniocampanaingreso.astype(int)\n",
    "dataset.campanaingreso = dataset.campanaingreso.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8224588c-d022-440b-8b5d-a60bfac26df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Balanceo\n",
    "# ========================\n",
    "def target_upsampler(dataset):\n",
    "    zero_size = dataset.clase.value_counts()[0]\n",
    "    df_majority = dataset[dataset.clase == 0]\n",
    "    df_minority = dataset[dataset.clase == 1]\n",
    "\n",
    "    df_minority_upsampled = resample(\n",
    "        df_minority,\n",
    "        replace=True,\n",
    "        n_samples=(zero_size // 4),\n",
    "        random_state=123,\n",
    "    )\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "    return df_upsampled\n",
    "\n",
    "df_upsampled = target_upsampler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031535d1-347a-4a5f-9386-31e575b9b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Split Data\n",
    "# ========================\n",
    "X = df_upsampled.drop([\"codvendedora\", \"clase\", \"aniocampana\"], axis=1)\n",
    "y = df_upsampled[\"clase\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50ab8690-891c-4a1a-8401-4a0eec1cfc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en y_train: [Decimal('0') Decimal('1')]\n",
      "Tipo de datos en y_train: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores únicos en y_train:\", y_train.unique())\n",
    "print(\"Tipo de datos en y_train:\", y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "499b4215-82f4-440d-a739-d80e4bd19992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que y_train e y_test sean enteros\n",
    "y_train = y_train.astype(float).astype(int)\n",
    "y_test = y_test.astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "738881d9-aca1-4e49-87d8-c10494e41af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte todas las columnas posibles a numéricas \n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Rellena valores faltantes que hayan aparecido\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2ca8b24-f710-44fb-9997-b337532f7bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:41:18,235] A new study created in memory with name: no-name-133544e6-d93e-4ea5-bb0c-99df14005b07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:41:22,755] Trial 0 finished with value: 0.48998101836662344 and parameters: {'learning_rate': 0.058593033394375924, 'max_depth': 8, 'num_leaves': 43, 'min_child_samples': 66, 'feature_fraction': 0.8738973649068345, 'bagging_fraction': 0.6345356066115276, 'bagging_freq': 6, 'reg_alpha': 0.26102610033414164, 'reg_lambda': 0.0979795236254386}. Best is trial 0 with value: 0.48998101836662344.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8738973649068345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8738973649068345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6345356066115276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345356066115276\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:41:27,003] Trial 1 finished with value: 0.4949153298295689 and parameters: {'learning_rate': 0.07635005740405154, 'max_depth': 26, 'num_leaves': 42, 'min_child_samples': 85, 'feature_fraction': 0.659223202820936, 'bagging_fraction': 0.8655144031440205, 'bagging_freq': 5, 'reg_alpha': 0.9797960546371784, 'reg_lambda': 0.2636618630630906}. Best is trial 1 with value: 0.4949153298295689.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.659223202820936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.659223202820936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8655144031440205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8655144031440205\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:41:31,782] Trial 2 finished with value: 0.43930681403638916 and parameters: {'learning_rate': 0.026469810508382454, 'max_depth': 21, 'num_leaves': 36, 'min_child_samples': 75, 'feature_fraction': 0.6033025236221016, 'bagging_fraction': 0.9803177020973035, 'bagging_freq': 4, 'reg_alpha': 0.6106771090037522, 'reg_lambda': 0.2166704706796978}. Best is trial 1 with value: 0.4949153298295689.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6033025236221016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6033025236221016\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9803177020973035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9803177020973035\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:41:35,074] Trial 3 finished with value: 0.4099799088419564 and parameters: {'learning_rate': 0.027512812838005784, 'max_depth': 5, 'num_leaves': 52, 'min_child_samples': 72, 'feature_fraction': 0.8455991767506736, 'bagging_fraction': 0.9050079768526644, 'bagging_freq': 6, 'reg_alpha': 0.9546593885688499, 'reg_lambda': 0.05362901973599199}. Best is trial 1 with value: 0.4949153298295689.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8455991767506736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8455991767506736\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9050079768526644, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9050079768526644\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:41:38,430] Trial 4 finished with value: 0.4817676388619175 and parameters: {'learning_rate': 0.06663555866315271, 'max_depth': 12, 'num_leaves': 27, 'min_child_samples': 51, 'feature_fraction': 0.607488717352287, 'bagging_fraction': 0.6024580918166302, 'bagging_freq': 10, 'reg_alpha': 0.6617393182976465, 'reg_lambda': 0.6472436455434188}. Best is trial 1 with value: 0.4949153298295689.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.607488717352287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.607488717352287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6024580918166302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6024580918166302\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:41:42,921] Trial 5 finished with value: 0.37691978160615525 and parameters: {'learning_rate': 0.015488105400595658, 'max_depth': 10, 'num_leaves': 53, 'min_child_samples': 85, 'feature_fraction': 0.6739971452296967, 'bagging_fraction': 0.9453265053536193, 'bagging_freq': 6, 'reg_alpha': 0.729901914087964, 'reg_lambda': 0.4389425388439281}. Best is trial 1 with value: 0.4949153298295689.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6739971452296967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6739971452296967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9453265053536193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9453265053536193\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:41:47,499] Trial 6 finished with value: 0.5186944366336556 and parameters: {'learning_rate': 0.08651855224194221, 'max_depth': 30, 'num_leaves': 53, 'min_child_samples': 37, 'feature_fraction': 0.7974266257995741, 'bagging_fraction': 0.8810880254411388, 'bagging_freq': 1, 'reg_alpha': 0.9681569803720437, 'reg_lambda': 0.032908502562215}. Best is trial 6 with value: 0.5186944366336556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7974266257995741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7974266257995741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8810880254411388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8810880254411388\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:41:51,282] Trial 7 finished with value: 0.4877983754088098 and parameters: {'learning_rate': 0.06004550986123514, 'max_depth': 21, 'num_leaves': 39, 'min_child_samples': 45, 'feature_fraction': 0.6656147883628036, 'bagging_fraction': 0.6145025091574635, 'bagging_freq': 2, 'reg_alpha': 0.08490243450371371, 'reg_lambda': 0.12179081376672263}. Best is trial 6 with value: 0.5186944366336556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6656147883628036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6656147883628036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6145025091574635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6145025091574635\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:41:57,280] Trial 8 finished with value: 0.4830248383865111 and parameters: {'learning_rate': 0.037405280537882925, 'max_depth': 17, 'num_leaves': 56, 'min_child_samples': 30, 'feature_fraction': 0.9792601811494854, 'bagging_fraction': 0.8892907413444289, 'bagging_freq': 3, 'reg_alpha': 0.6554707656649338, 'reg_lambda': 0.00804822465204924}. Best is trial 6 with value: 0.5186944366336556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9792601811494854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9792601811494854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892907413444289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8892907413444289\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:01,825] Trial 9 finished with value: 0.4345629959297817 and parameters: {'learning_rate': 0.022380520082436472, 'max_depth': 29, 'num_leaves': 48, 'min_child_samples': 20, 'feature_fraction': 0.6255111642057356, 'bagging_fraction': 0.9391810855980575, 'bagging_freq': 5, 'reg_alpha': 0.44701229719254265, 'reg_lambda': 0.23347332128400122}. Best is trial 6 with value: 0.5186944366336556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6255111642057356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6255111642057356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9391810855980575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9391810855980575\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:04,783] Trial 10 finished with value: 0.49481166868193877 and parameters: {'learning_rate': 0.09847050781835417, 'max_depth': 30, 'num_leaves': 24, 'min_child_samples': 38, 'feature_fraction': 0.7677179536222242, 'bagging_fraction': 0.7575629536067455, 'bagging_freq': 1, 'reg_alpha': 0.8166993253904766, 'reg_lambda': 0.9172797007927408}. Best is trial 6 with value: 0.5186944366336556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7677179536222242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677179536222242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7575629536067455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7575629536067455\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:09,395] Trial 11 finished with value: 0.5172756131774678 and parameters: {'learning_rate': 0.0867850658641263, 'max_depth': 26, 'num_leaves': 60, 'min_child_samples': 95, 'feature_fraction': 0.7479641750991015, 'bagging_fraction': 0.8202493136812269, 'bagging_freq': 9, 'reg_alpha': 0.994558918283772, 'reg_lambda': 0.44832993827094236}. Best is trial 6 with value: 0.5186944366336556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7479641750991015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479641750991015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8202493136812269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202493136812269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:14,052] Trial 12 finished with value: 0.5177183937949918 and parameters: {'learning_rate': 0.09579515105116977, 'max_depth': 25, 'num_leaves': 58, 'min_child_samples': 97, 'feature_fraction': 0.7599324164974453, 'bagging_fraction': 0.8042682600644669, 'bagging_freq': 9, 'reg_alpha': 0.8569731453171032, 'reg_lambda': 0.5617955328648299}. Best is trial 6 with value: 0.5186944366336556.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7599324164974453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599324164974453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8042682600644669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042682600644669\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:19,017] Trial 13 finished with value: 0.5255313010168573 and parameters: {'learning_rate': 0.09562585058946195, 'max_depth': 24, 'num_leaves': 60, 'min_child_samples': 19, 'feature_fraction': 0.8259017309102592, 'bagging_fraction': 0.7231959367902172, 'bagging_freq': 8, 'reg_alpha': 0.8353237655274858, 'reg_lambda': 0.6788665463642329}. Best is trial 13 with value: 0.5255313010168573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259017309102592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259017309102592\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7231959367902172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7231959367902172\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:23,557] Trial 14 finished with value: 0.5098178864221636 and parameters: {'learning_rate': 0.07807065127337136, 'max_depth': 22, 'num_leaves': 50, 'min_child_samples': 11, 'feature_fraction': 0.8961589639674382, 'bagging_fraction': 0.7094502419157096, 'bagging_freq': 8, 'reg_alpha': 0.4385689330866954, 'reg_lambda': 0.81467097611692}. Best is trial 13 with value: 0.5255313010168573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8961589639674382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8961589639674382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7094502419157096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7094502419157096\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:27,491] Trial 15 finished with value: 0.49952608165193035 and parameters: {'learning_rate': 0.08585231864782569, 'max_depth': 16, 'num_leaves': 32, 'min_child_samples': 28, 'feature_fraction': 0.94079850350573, 'bagging_fraction': 0.7058186471716692, 'bagging_freq': 8, 'reg_alpha': 0.8190614853317885, 'reg_lambda': 0.7189310884695302}. Best is trial 13 with value: 0.5255313010168573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94079850350573, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94079850350573\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7058186471716692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7058186471716692\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:31,597] Trial 16 finished with value: 0.4863976164341147 and parameters: {'learning_rate': 0.047454729819334324, 'max_depth': 30, 'num_leaves': 46, 'min_child_samples': 13, 'feature_fraction': 0.8219127898644105, 'bagging_fraction': 0.7461927783010645, 'bagging_freq': 1, 'reg_alpha': 0.5357575905109143, 'reg_lambda': 0.9075011403564718}. Best is trial 13 with value: 0.5255313010168573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8219127898644105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219127898644105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7461927783010645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7461927783010645\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:36,373] Trial 17 finished with value: 0.5049996440258122 and parameters: {'learning_rate': 0.07109989863545424, 'max_depth': 24, 'num_leaves': 55, 'min_child_samples': 36, 'feature_fraction': 0.7069598955251164, 'bagging_fraction': 0.6730662669274331, 'bagging_freq': 7, 'reg_alpha': 0.8564427689338825, 'reg_lambda': 0.3386040477331515}. Best is trial 13 with value: 0.5255313010168573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069598955251164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069598955251164\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6730662669274331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730662669274331\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:41,511] Trial 18 finished with value: 0.5218499386625509 and parameters: {'learning_rate': 0.08837815756001005, 'max_depth': 28, 'num_leaves': 60, 'min_child_samples': 25, 'feature_fraction': 0.8027696315848205, 'bagging_fraction': 0.8332503043586978, 'bagging_freq': 3, 'reg_alpha': 0.3025727783661363, 'reg_lambda': 0.5942790957565964}. Best is trial 13 with value: 0.5255313010168573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8027696315848205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8027696315848205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8332503043586978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332503043586978\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:46,822] Trial 19 finished with value: 0.528932554334879 and parameters: {'learning_rate': 0.0982218494479507, 'max_depth': 19, 'num_leaves': 60, 'min_child_samples': 23, 'feature_fraction': 0.9100030524729843, 'bagging_fraction': 0.8379374504691287, 'bagging_freq': 3, 'reg_alpha': 0.30708869889317825, 'reg_lambda': 0.5751847456749801}. Best is trial 19 with value: 0.528932554334879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9100030524729843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9100030524729843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8379374504691287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8379374504691287\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:51,956] Trial 20 finished with value: 0.4814892790979157 and parameters: {'learning_rate': 0.04625977181264952, 'max_depth': 15, 'num_leaves': 46, 'min_child_samples': 58, 'feature_fraction': 0.9157650839079889, 'bagging_fraction': 0.7656044939331432, 'bagging_freq': 4, 'reg_alpha': 0.03357456039030349, 'reg_lambda': 0.7580461354760981}. Best is trial 19 with value: 0.528932554334879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9157650839079889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9157650839079889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7656044939331432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7656044939331432\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:42:56,887] Trial 21 finished with value: 0.5292237898550062 and parameters: {'learning_rate': 0.09972667854831817, 'max_depth': 23, 'num_leaves': 60, 'min_child_samples': 23, 'feature_fraction': 0.8549754396255432, 'bagging_fraction': 0.847060082911702, 'bagging_freq': 3, 'reg_alpha': 0.30099561997132496, 'reg_lambda': 0.547277085001394}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:43:01,914] Trial 22 finished with value: 0.5268140059548417 and parameters: {'learning_rate': 0.09947640055274709, 'max_depth': 19, 'num_leaves': 56, 'min_child_samples': 19, 'feature_fraction': 0.8590434097551555, 'bagging_fraction': 0.8488315969058686, 'bagging_freq': 3, 'reg_alpha': 0.2873232870050028, 'reg_lambda': 0.5059466620456128}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8590434097551555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8590434097551555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8488315969058686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488315969058686\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:43:07,301] Trial 23 finished with value: 0.5267591195062957 and parameters: {'learning_rate': 0.09847827634350652, 'max_depth': 19, 'num_leaves': 56, 'min_child_samples': 19, 'feature_fraction': 0.864291999477204, 'bagging_fraction': 0.8448046969623106, 'bagging_freq': 2, 'reg_alpha': 0.25042624467557284, 'reg_lambda': 0.40886724386383866}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864291999477204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864291999477204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8448046969623106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448046969623106\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:43:12,577] Trial 24 finished with value: 0.5162131415802037 and parameters: {'learning_rate': 0.07934585213752719, 'max_depth': 19, 'num_leaves': 56, 'min_child_samples': 44, 'feature_fraction': 0.9975052253513054, 'bagging_fraction': 0.7988095799719386, 'bagging_freq': 3, 'reg_alpha': 0.17347833250421213, 'reg_lambda': 0.5171513890963991}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975052253513054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975052253513054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988095799719386, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988095799719386\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:43:17,520] Trial 25 finished with value: 0.5187128225853967 and parameters: {'learning_rate': 0.09167525185079016, 'max_depth': 14, 'num_leaves': 50, 'min_child_samples': 10, 'feature_fraction': 0.9391530272667028, 'bagging_fraction': 0.7838252682948597, 'bagging_freq': 4, 'reg_alpha': 0.35364608705136485, 'reg_lambda': 0.5923991706487267}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9391530272667028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9391530272667028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7838252682948597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7838252682948597\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:43:23,091] Trial 26 finished with value: 0.515184926066661 and parameters: {'learning_rate': 0.07991532970899254, 'max_depth': 19, 'num_leaves': 57, 'min_child_samples': 31, 'feature_fraction': 0.8989266556329267, 'bagging_fraction': 0.9187396885393287, 'bagging_freq': 2, 'reg_alpha': 0.15983867823746073, 'reg_lambda': 0.33910486526526357}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8989266556329267, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8989266556329267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9187396885393287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9187396885393287\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:43:28,321] Trial 27 finished with value: 0.5056902672745757 and parameters: {'learning_rate': 0.06888140872724181, 'max_depth': 22, 'num_leaves': 53, 'min_child_samples': 23, 'feature_fraction': 0.9593359503928032, 'bagging_fraction': 0.8522215257098691, 'bagging_freq': 3, 'reg_alpha': 0.3746042779228581, 'reg_lambda': 0.49933143842575095}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9593359503928032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9593359503928032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8522215257098691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522215257098691\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:43:31,900] Trial 28 finished with value: 0.489255065227258 and parameters: {'learning_rate': 0.09224248296363309, 'max_depth': 18, 'num_leaves': 20, 'min_child_samples': 16, 'feature_fraction': 0.867385789743004, 'bagging_fraction': 0.9829198707172184, 'bagging_freq': 4, 'reg_alpha': 0.15528010741199988, 'reg_lambda': 0.7924660129025092}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.867385789743004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.867385789743004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829198707172184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829198707172184\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:43:38,088] Trial 29 finished with value: 0.17159890265215197 and parameters: {'learning_rate': 0.005775013513560752, 'max_depth': 21, 'num_leaves': 60, 'min_child_samples': 56, 'feature_fraction': 0.8897459435456506, 'bagging_fraction': 0.8714515499737794, 'bagging_freq': 5, 'reg_alpha': 0.26415956164938287, 'reg_lambda': 0.36638277724351503}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897459435456506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897459435456506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8714515499737794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8714515499737794\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:43:43,105] Trial 30 finished with value: 0.4929350077339432 and parameters: {'learning_rate': 0.05643055403256528, 'max_depth': 14, 'num_leaves': 45, 'min_child_samples': 46, 'feature_fraction': 0.9208085523959619, 'bagging_fraction': 0.8150987833821507, 'bagging_freq': 2, 'reg_alpha': 0.5261702074947869, 'reg_lambda': 0.5106076095810717}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9208085523959619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208085523959619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150987833821507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150987833821507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:43:48,168] Trial 31 finished with value: 0.5267056414269339 and parameters: {'learning_rate': 0.09868133729359013, 'max_depth': 19, 'num_leaves': 57, 'min_child_samples': 19, 'feature_fraction': 0.8545336648842858, 'bagging_fraction': 0.8430145164971202, 'bagging_freq': 2, 'reg_alpha': 0.2268586207555738, 'reg_lambda': 0.4137100773660769}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8545336648842858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8545336648842858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8430145164971202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430145164971202\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:43:53,617] Trial 32 finished with value: 0.5258879420966018 and parameters: {'learning_rate': 0.09915873616728137, 'max_depth': 17, 'num_leaves': 55, 'min_child_samples': 33, 'feature_fraction': 0.8726523904100262, 'bagging_fraction': 0.8498205224688974, 'bagging_freq': 3, 'reg_alpha': 0.34683477510234184, 'reg_lambda': 0.640757560465073}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8726523904100262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8726523904100262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8498205224688974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8498205224688974\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:43:58,840] Trial 33 finished with value: 0.5146406413165753 and parameters: {'learning_rate': 0.08322561847666647, 'max_depth': 23, 'num_leaves': 50, 'min_child_samples': 25, 'feature_fraction': 0.8380164925240017, 'bagging_fraction': 0.9066317038082761, 'bagging_freq': 2, 'reg_alpha': 0.2307708263027216, 'reg_lambda': 0.28348678984947984}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380164925240017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380164925240017\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9066317038082761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9066317038082761\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:03,861] Trial 34 finished with value: 0.5194098424476548 and parameters: {'learning_rate': 0.09125263562915517, 'max_depth': 20, 'num_leaves': 54, 'min_child_samples': 17, 'feature_fraction': 0.8024125843174211, 'bagging_fraction': 0.7881902902648382, 'bagging_freq': 4, 'reg_alpha': 0.3994925544454837, 'reg_lambda': 0.47407639180193273}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8024125843174211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8024125843174211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7881902902648382, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7881902902648382\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:08,055] Trial 35 finished with value: 0.5022122643152601 and parameters: {'learning_rate': 0.0753166556194873, 'max_depth': 26, 'num_leaves': 40, 'min_child_samples': 25, 'feature_fraction': 0.8604464944287471, 'bagging_fraction': 0.8669603506457345, 'bagging_freq': 1, 'reg_alpha': 0.2910745022074678, 'reg_lambda': 0.5481717604579313}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604464944287471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604464944287471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669603506457345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669603506457345\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:13,660] Trial 36 finished with value: 0.520681744564667 and parameters: {'learning_rate': 0.09287400564787351, 'max_depth': 13, 'num_leaves': 58, 'min_child_samples': 62, 'feature_fraction': 0.8805796327948496, 'bagging_fraction': 0.9499641242269253, 'bagging_freq': 5, 'reg_alpha': 0.1186837137326815, 'reg_lambda': 0.39775493225423747}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8805796327948496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8805796327948496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499641242269253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499641242269253\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:17,256] Trial 37 finished with value: 0.4899736141538895 and parameters: {'learning_rate': 0.09992884939485921, 'max_depth': 5, 'num_leaves': 51, 'min_child_samples': 14, 'feature_fraction': 0.9185847603291621, 'bagging_fraction': 0.8279849233779305, 'bagging_freq': 3, 'reg_alpha': 0.00018201245495896856, 'reg_lambda': 0.30095347357379987}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9185847603291621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9185847603291621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8279849233779305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279849233779305\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:21,669] Trial 38 finished with value: 0.48812634922692294 and parameters: {'learning_rate': 0.06240297047338644, 'max_depth': 16, 'num_leaves': 34, 'min_child_samples': 74, 'feature_fraction': 0.8423759162107137, 'bagging_fraction': 0.8962035974481678, 'bagging_freq': 2, 'reg_alpha': 0.47707317544408645, 'reg_lambda': 0.6376887661134056}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8423759162107137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8423759162107137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962035974481678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962035974481678\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:25,997] Trial 39 finished with value: 0.5065561136428048 and parameters: {'learning_rate': 0.08289508412366911, 'max_depth': 10, 'num_leaves': 42, 'min_child_samples': 38, 'feature_fraction': 0.7870813933306093, 'bagging_fraction': 0.8581137444965008, 'bagging_freq': 6, 'reg_alpha': 0.21281719989927494, 'reg_lambda': 0.14132208066935464}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870813933306093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870813933306093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581137444965008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8581137444965008\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:31,646] Trial 40 finished with value: 0.5098552400018521 and parameters: {'learning_rate': 0.07397585005502735, 'max_depth': 20, 'num_leaves': 52, 'min_child_samples': 51, 'feature_fraction': 0.9548700213674177, 'bagging_fraction': 0.9226125058622042, 'bagging_freq': 4, 'reg_alpha': 0.32230491078708856, 'reg_lambda': 0.44590993036124976}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548700213674177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548700213674177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9226125058622042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9226125058622042\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:36,704] Trial 41 finished with value: 0.527884037190536 and parameters: {'learning_rate': 0.09632248475575494, 'max_depth': 18, 'num_leaves': 58, 'min_child_samples': 21, 'feature_fraction': 0.8582312846615451, 'bagging_fraction': 0.8320664638572454, 'bagging_freq': 2, 'reg_alpha': 0.25360848876152725, 'reg_lambda': 0.4011691403998935}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8582312846615451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8582312846615451\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8320664638572454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8320664638572454\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:41,510] Trial 42 finished with value: 0.5272052118467805 and parameters: {'learning_rate': 0.0936648216745142, 'max_depth': 18, 'num_leaves': 58, 'min_child_samples': 22, 'feature_fraction': 0.8344056844144478, 'bagging_fraction': 0.8842800364924533, 'bagging_freq': 1, 'reg_alpha': 0.26122238621592825, 'reg_lambda': 0.386728253330494}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8344056844144478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8344056844144478\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8842800364924533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8842800364924533\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:46,176] Trial 43 finished with value: 0.5221597202108565 and parameters: {'learning_rate': 0.0900952488094739, 'max_depth': 17, 'num_leaves': 58, 'min_child_samples': 22, 'feature_fraction': 0.816639350572362, 'bagging_fraction': 0.879673211721013, 'bagging_freq': 1, 'reg_alpha': 0.11127720724874113, 'reg_lambda': 0.558735241860733}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816639350572362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816639350572362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.879673211721013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.879673211721013\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:50,653] Trial 44 finished with value: 0.5269052962408688 and parameters: {'learning_rate': 0.09545000919452148, 'max_depth': 11, 'num_leaves': 58, 'min_child_samples': 28, 'feature_fraction': 0.8389512126869313, 'bagging_fraction': 0.8154512006641622, 'bagging_freq': 1, 'reg_alpha': 0.20305624948726927, 'reg_lambda': 0.478480197962227}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8389512126869313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8389512126869313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8154512006641622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154512006641622\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:54,935] Trial 45 finished with value: 0.5211050571377409 and parameters: {'learning_rate': 0.08319877859698036, 'max_depth': 11, 'num_leaves': 59, 'min_child_samples': 28, 'feature_fraction': 0.78550807985018, 'bagging_fraction': 0.777850544846867, 'bagging_freq': 1, 'reg_alpha': 0.4064629504690993, 'reg_lambda': 0.22754500111850565}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78550807985018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78550807985018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777850544846867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777850544846867\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:44:58,774] Trial 46 finished with value: 0.5085060071037606 and parameters: {'learning_rate': 0.09517163545464015, 'max_depth': 7, 'num_leaves': 54, 'min_child_samples': 41, 'feature_fraction': 0.7322967029559284, 'bagging_fraction': 0.8118153569869899, 'bagging_freq': 1, 'reg_alpha': 0.19183727295189393, 'reg_lambda': 0.3639694797611186}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7322967029559284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322967029559284\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118153569869899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118153569869899\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:45:02,991] Trial 47 finished with value: 0.512217058230802 and parameters: {'learning_rate': 0.08692631075864085, 'max_depth': 8, 'num_leaves': 48, 'min_child_samples': 34, 'feature_fraction': 0.8348266247412006, 'bagging_fraction': 0.8272670504147418, 'bagging_freq': 1, 'reg_alpha': 0.0922297784476779, 'reg_lambda': 0.16667089964209336}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8348266247412006, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8348266247412006\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272670504147418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8272670504147418\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:45:08,454] Trial 48 finished with value: 0.5271311666749627 and parameters: {'learning_rate': 0.09484205728566018, 'max_depth': 22, 'num_leaves': 58, 'min_child_samples': 28, 'feature_fraction': 0.8968428445778304, 'bagging_fraction': 0.8899563096464167, 'bagging_freq': 2, 'reg_alpha': 0.3188729884741733, 'reg_lambda': 0.6011457568410519}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968428445778304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968428445778304\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8899563096464167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8899563096464167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12707\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201089 -> initscore=-1.379501\n",
      "[LightGBM] [Info] Start training from score -1.379501\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12671\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Info] Number of positive: 10633, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12656\n",
      "[LightGBM] [Info] Number of data points in the train set: 52882, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201070 -> initscore=-1.379618\n",
      "[LightGBM] [Info] Start training from score -1.379618\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12677\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "[LightGBM] [Info] Number of positive: 10634, number of negative: 42249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12687\n",
      "[LightGBM] [Info] Number of data points in the train set: 52883, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201085 -> initscore=-1.379524\n",
      "[LightGBM] [Info] Start training from score -1.379524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 23:45:14,549] Trial 49 finished with value: 0.5228843993470391 and parameters: {'learning_rate': 0.08873470867984212, 'max_depth': 23, 'num_leaves': 60, 'min_child_samples': 81, 'feature_fraction': 0.9064232859699844, 'bagging_fraction': 0.9500901369717872, 'bagging_freq': 2, 'reg_alpha': 0.5769874271505117, 'reg_lambda': 0.7040098705203544}. Best is trial 21 with value: 0.5292237898550062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064232859699844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064232859699844\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9500901369717872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500901369717872\n",
      "Los mejores parámetros son: {'learning_rate': 0.09972667854831817, 'max_depth': 23, 'num_leaves': 60, 'min_child_samples': 23, 'feature_fraction': 0.8549754396255432, 'bagging_fraction': 0.847060082911702, 'bagging_freq': 3, 'reg_alpha': 0.30099561997132496, 'reg_lambda': 0.547277085001394}\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] Number of positive: 13292, number of negative: 52811\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12757\n",
      "[LightGBM] [Info] Number of data points in the train set: 66103, number of used features: 78\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201080 -> initscore=-1.379557\n",
      "[LightGBM] [Info] Start training from score -1.379557\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's binary_logloss: 0.358189\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] Number of positive: 13292, number of negative: 52811\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12757\n",
      "[LightGBM] [Info] Number of data points in the train set: 66103, number of used features: 78\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201080 -> initscore=-1.379557\n",
      "[LightGBM] [Info] Start training from score -1.379557\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.340111\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] Number of positive: 13292, number of negative: 52811\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12757\n",
      "[LightGBM] [Info] Number of data points in the train set: 66103, number of used features: 78\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201080 -> initscore=-1.379557\n",
      "[LightGBM] [Info] Start training from score -1.379557\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[250]\tvalid_0's binary_logloss: 0.313432\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] Number of positive: 13292, number of negative: 52811\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12757\n",
      "[LightGBM] [Info] Number of data points in the train set: 66103, number of used features: 78\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201080 -> initscore=-1.379557\n",
      "[LightGBM] [Info] Start training from score -1.379557\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's binary_logloss: 0.292653\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] Number of positive: 13292, number of negative: 52811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12757\n",
      "[LightGBM] [Info] Number of data points in the train set: 66103, number of used features: 78\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201080 -> initscore=-1.379557\n",
      "[LightGBM] [Info] Start training from score -1.379557\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[843]\tvalid_0's binary_logloss: 0.284701\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.847060082911702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.847060082911702\n",
      "\n",
      "Resultados por número de estimadores:\n",
      "  Número de estimadores  Accuracy  F1_score  Precision  Recall\n",
      "0                  N=50    0.8538    0.4907     0.7861  0.3566\n",
      "1                 N=100    0.8619    0.5334     0.8014  0.3997\n",
      "2                 N=250    0.8769    0.6039     0.8283  0.4752\n",
      "3                 N=500    0.8958    0.6830     0.8549  0.5686\n",
      "4                N=1000    0.9057    0.7212     0.8662  0.6178\n"
     ]
    }
   ],
   "source": [
    "# Construcción del MODELO 1\n",
    "\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "# =============================================\n",
    "# 1. Optuna para encontrar mejores parámetros LGBM\n",
    "# =============================================\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 60),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        'n_estimators': 100,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Ejecutar optimización\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Los mejores parámetros son:\", study.best_params)\n",
    "\n",
    "# ============================\n",
    "# 2. Evaluar n_estimators múltiples\n",
    "# ============================\n",
    "best_params = study.best_params.copy()  # Copia para no modificar directamente\n",
    "\n",
    "n_estimators_list = [50, 100, 250, 500, 1000]\n",
    "resultados = []\n",
    "\n",
    "for n in n_estimators_list:\n",
    "    best_params['n_estimators'] = n\n",
    "    model = LGBMClassifier(**best_params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        callbacks=[early_stopping(stopping_rounds=200)],\n",
    "    )\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    resultados.append({\n",
    "        'Número de estimadores': f'N={n}',\n",
    "        'Accuracy': round(accuracy_score(y_test, pred), 4),\n",
    "        'F1_score': round(f1_score(y_test, pred), 4),\n",
    "        'Precision': round(precision_score(y_test, pred), 4),\n",
    "        'Recall': round(recall_score(y_test, pred), 4)\n",
    "    })\n",
    "\n",
    "# Mostrar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(\"\\nResultados por número de estimadores:\")\n",
    "print(df_resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea39940a-c360-456b-b0b2-035c77be33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los mejores parámetros son: {'learning_rate': 0.09972667854831817, 'max_depth': 23, 'num_leaves': 60, 'min_child_samples': 23, 'feature_fraction': 0.8549754396255432, 'bagging_fraction': 0.847060082911702, 'bagging_freq': 3, 'reg_alpha': 0.30099561997132496, 'reg_lambda': 0.547277085001394}\n"
     ]
    }
   ],
   "source": [
    "print(\"Los mejores parámetros son:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0fe98ef-d627-4b77-9891-26e37bf971c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Gráficas de Rendimiento\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datos del rendimiento del modelo para cada número de estimadores\n",
    "estimadores = [50, 100, 250, 500, 1000]\n",
    "accuracy = [0.854, 0.859, 0.875, 0.895, 0.905]\n",
    "f1_score = [0.495, 0.522, 0.596, 0.680, 0.721]\n",
    "precision = [0.775, 0.788, 0.818, 0.847, 0.860]\n",
    "recall = [0.364, 0.390, 0.469, 0.569, 0.621]\n",
    "\n",
    "# Crear gráfico de líneas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(estimadores, accuracy, marker='o', label='Accuracy')\n",
    "plt.plot(estimadores, f1_score, marker='o', label='F1-score')\n",
    "plt.plot(estimadores, precision, marker='o', label='Precisión')\n",
    "plt.plot(estimadores, recall, marker='o', label='Recall')\n",
    "\n",
    "plt.title('Desempeño del modelo LightGBM según número de estimadores')\n",
    "plt.xlabel('Número de estimadores')\n",
    "plt.ylabel('Valor de la métrica')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f2b3b9a-ceea-4020-9ac7-04cff1c557bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Número de estimadores  Accuracy  F1_score  Precision  Recall\n",
      "0                  N=50    0.8439    0.3934     0.8450  0.2563\n",
      "1                 N=100    0.8454    0.4021     0.8505  0.2633\n",
      "2                 N=250    0.8449    0.3985     0.8500  0.2603\n",
      "3                 N=500    0.8448    0.4001     0.8450  0.2621\n",
      "4                N=1000    0.8455    0.4029     0.8503  0.2640\n"
     ]
    }
   ],
   "source": [
    "#MODELO 2: RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "\n",
    "# Lista de estimadores a probar\n",
    "estimadores_rf = [50, 100, 250, 500, 1000]\n",
    "\n",
    "# Lista para guardar los resultados\n",
    "resultados_rf = []\n",
    "\n",
    "for n in estimadores_rf:\n",
    "    model_rf = RandomForestClassifier(n_estimators=n, max_depth=10, random_state=42)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "    resultados_rf.append({\n",
    "        'Número de estimadores': f'N={n}',\n",
    "        'Accuracy': round(accuracy_score(y_test, pred_rf), 4),\n",
    "        'F1_score': round(f1_score(y_test, pred_rf), 4),\n",
    "        'Precision': round(precision_score(y_test, pred_rf), 4),\n",
    "        'Recall': round(recall_score(y_test, pred_rf), 4)\n",
    "    })\n",
    "\n",
    "# Convertir a DataFrame para visualizar\n",
    "df_resultados_rf = pd.DataFrame(resultados_rf)\n",
    "print(df_resultados_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1569f57-ee73-45ac-b54d-1a4702a080d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Datos reales proporcionados por el usuario para Random Forest\n",
    "estimadores_rf = [50, 100, 250, 500, 1000]\n",
    "accuracy_rf = [0.8439, 0.8454, 0.8449, 0.8448, 0.8455]\n",
    "f1_rf = [0.3934, 0.4021, 0.3985, 0.4001, 0.4029]\n",
    "precision_rf = [0.8450, 0.8505, 0.8500, 0.8450, 0.8503]\n",
    "recall_rf = [0.2563, 0.2633, 0.2603, 0.2621, 0.2640]\n",
    "\n",
    "# Crear gráfico de líneas con los resultados reales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(estimadores_rf, accuracy_rf, marker='o', label='Accuracy')\n",
    "plt.plot(estimadores_rf, f1_rf, marker='o', label='F1-score')\n",
    "plt.plot(estimadores_rf, precision_rf, marker='o', label='Precisión')\n",
    "plt.plot(estimadores_rf, recall_rf, marker='o', label='Recall')\n",
    "\n",
    "plt.title('Desempeño del modelo Random Forest según número de estimadores')\n",
    "plt.xlabel('Número de estimadores')\n",
    "plt.ylabel('Valor de la métrica')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b008e751-8a23-45ef-8bd5-c630cab5b856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_iter  Accuracy  F1_score  Precision  Recall\n",
      "0       50    0.8025    0.0000     0.0000  0.0000\n",
      "1      100    0.8023    0.0004     0.1250  0.0002\n",
      "2      250    0.8023    0.0007     0.1818  0.0004\n",
      "3      500    0.8019    0.0011     0.1250  0.0005\n",
      "4     1000    0.8022    0.0007     0.1429  0.0004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "\n",
    "# Valores de max_iter a probar\n",
    "iteraciones = [50, 100, 250, 500, 1000]\n",
    "\n",
    "# Guardar resultados\n",
    "resultados_lr = []\n",
    "\n",
    "for it in iteraciones:\n",
    "    model_lr = LogisticRegression(max_iter=it, random_state=42)\n",
    "    model_lr.fit(X_train, y_train)\n",
    "    pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "    resultados_lr.append({\n",
    "        'max_iter': f'{it}',\n",
    "        'Accuracy': round(accuracy_score(y_test, pred_lr), 4),\n",
    "        'F1_score': round(f1_score(y_test, pred_lr), 4),\n",
    "        'Precision': round(precision_score(y_test, pred_lr), 4),\n",
    "        'Recall': round(recall_score(y_test, pred_lr), 4)\n",
    "    })\n",
    "\n",
    "df_resultados_lr = pd.DataFrame(resultados_lr)\n",
    "print(df_resultados_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcde9d90-1195-4510-a523-3d8840f115bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Datos reales proporcionados por el usuario para Regresión Logística\n",
    "iteraciones = [50, 100, 250, 500, 1000]\n",
    "accuracy_lr = [0.8025, 0.8023, 0.8023, 0.8019, 0.8022]\n",
    "f1_lr = [0.0, 0.0004, 0.0007, 0.0011, 0.0007]\n",
    "precision_lr = [0.0, 0.1250, 0.1818, 0.1250, 0.1429]\n",
    "recall_lr = [0.0, 0.0002, 0.0004, 0.0005, 0.0004]\n",
    "\n",
    "# Crear gráfico de líneas con los resultados reales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iteraciones, accuracy_lr, marker='o', label='Accuracy')\n",
    "plt.plot(iteraciones, f1_lr, marker='o', label='F1-score')\n",
    "plt.plot(iteraciones, precision_lr, marker='o', label='Precisión')\n",
    "plt.plot(iteraciones, recall_lr, marker='o', label='Recall')\n",
    "\n",
    "plt.title('Desempeño del modelo Regresión Logística según número de iteraciones (max_iter)')\n",
    "plt.xlabel('max_iter')\n",
    "plt.ylabel('Valor de la métrica')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "009c7501-920e-4cb3-bc90-5efda1bee58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Número de estimadores  Accuracy  F1_score  Precision  Recall\n",
      "0                  N=50    0.8566    0.5229     0.7623  0.3979\n",
      "1                 N=100    0.8679    0.5784     0.7821  0.4589\n",
      "2                 N=250    0.8888    0.6703     0.8086  0.5724\n",
      "3                 N=500    0.9018    0.7181     0.8290  0.6334\n",
      "4                N=1000    0.9028    0.7207     0.8325  0.6353\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "\n",
    "# Lista de estimadores a evaluar\n",
    "estimadores_xgb = [50, 100, 250, 500, 1000]\n",
    "\n",
    "# Lista para guardar resultados\n",
    "resultados_xgb = []\n",
    "\n",
    "for n in estimadores_xgb:\n",
    "    model_xgb = XGBClassifier(n_estimators=n, use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "    resultados_xgb.append({\n",
    "        'Número de estimadores': f'N={n}',\n",
    "        'Accuracy': round(accuracy_score(y_test, pred_xgb), 4),\n",
    "        'F1_score': round(f1_score(y_test, pred_xgb), 4),\n",
    "        'Precision': round(precision_score(y_test, pred_xgb), 4),\n",
    "        'Recall': round(recall_score(y_test, pred_xgb), 4)\n",
    "    })\n",
    "\n",
    "# Convertir a DataFrame para ver resultados\n",
    "df_resultados_xgb = pd.DataFrame(resultados_xgb)\n",
    "print(df_resultados_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dae2a14a-5666-4300-a857-fa5f96b4f443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Datos reales proporcionados por el usuario para XGBoost\n",
    "estimadores_xgb = [50, 100, 250, 500, 1000]\n",
    "accuracy_xgb = [0.8566, 0.8679, 0.8888, 0.9018, 0.9028]\n",
    "f1_xgb = [0.5229, 0.5784, 0.6703, 0.7181, 0.7207]\n",
    "precision_xgb = [0.7623, 0.7821, 0.8086, 0.8290, 0.8325]\n",
    "recall_xgb = [0.3979, 0.4589, 0.5724, 0.6334, 0.6353]\n",
    "\n",
    "# Crear gráfico de líneas con los resultados reales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(estimadores_xgb, accuracy_xgb, marker='o', label='Accuracy')\n",
    "plt.plot(estimadores_xgb, f1_xgb, marker='o', label='F1-score')\n",
    "plt.plot(estimadores_xgb, precision_xgb, marker='o', label='Precisión')\n",
    "plt.plot(estimadores_xgb, recall_xgb, marker='o', label='Recall')\n",
    "\n",
    "plt.title('Desempeño del modelo XGBoost según número de estimadores')\n",
    "plt.xlabel('Número de estimadores')\n",
    "plt.ylabel('Valor de la métrica')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b36ac315-50b3-4401-b870-471ff8c1da9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Info] Number of positive: 13292, number of negative: 52811\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12757\n",
      "[LightGBM] [Info] Number of data points in the train set: 66103, number of used features: 78\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201080 -> initscore=-1.379557\n",
      "[LightGBM] [Info] Start training from score -1.379557\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[848]\tvalid_0's binary_logloss: 0.285019\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549754396255432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549754396255432\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "# =============================================\n",
    "# 1. LightGBM con hiperparámetros óptimos de Optuna\n",
    "# =============================================\n",
    "best_params = {\n",
    "    'learning_rate': 0.09972667854831817,\n",
    "    'max_depth': 23,\n",
    "    'num_leaves': 60,\n",
    "    'min_child_samples': 23,\n",
    "    'feature_fraction': 0.8549754396255432,\n",
    "    'subsample': 0.847060082911702,\n",
    "    'subsample_freq': 3,\n",
    "    'reg_alpha': 0.30099561997132496,\n",
    "    'reg_lambda': 0.547277085001394,\n",
    "    'n_estimators': 1000,\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "model_lgbm = LGBMClassifier(**best_params)\n",
    "model_lgbm.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    callbacks=[early_stopping(stopping_rounds=200)]\n",
    ")\n",
    "pred_lgbm = model_lgbm.predict(X_test)\n",
    "report_lgbm = classification_report(y_test, pred_lgbm, output_dict=True)\n",
    "\n",
    "# =============================================\n",
    "# 2. Random Forest\n",
    "# =============================================\n",
    "model_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "pred_rf = model_rf.predict(X_test)\n",
    "report_rf = classification_report(y_test, pred_rf, output_dict=True)\n",
    "\n",
    "# =============================================\n",
    "# 3. Logistic Regression\n",
    "# =============================================\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_lr.fit(X_train, y_train)\n",
    "pred_lr = model_lr.predict(X_test)\n",
    "report_lr = classification_report(y_test, pred_lr, output_dict=True)\n",
    "\n",
    "# =============================================\n",
    "# 4. XGBoost\n",
    "# =============================================\n",
    "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "pred_xgb = model_xgb.predict(X_test)\n",
    "report_xgb = classification_report(y_test, pred_xgb, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "839628ea-a8bc-4c1e-9436-76f025d042ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Diccionario con métricas reales \n",
    "metrics_summary = {\n",
    "    \"LightGBM\": {\n",
    "        \"Accuracy\": report_lgbm[\"accuracy\"],\n",
    "        \"F1_score\": report_lgbm[\"weighted avg\"][\"f1-score\"],\n",
    "        \"Precision\": report_lgbm[\"weighted avg\"][\"precision\"],\n",
    "        \"Recall\": report_lgbm[\"weighted avg\"][\"recall\"]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"Accuracy\": report_rf[\"accuracy\"],\n",
    "        \"F1_score\": report_rf[\"weighted avg\"][\"f1-score\"],\n",
    "        \"Precision\": report_rf[\"weighted avg\"][\"precision\"],\n",
    "        \"Recall\": report_rf[\"weighted avg\"][\"recall\"]\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"Accuracy\": report_lr[\"accuracy\"],\n",
    "        \"F1_score\": report_lr[\"weighted avg\"][\"f1-score\"],\n",
    "        \"Precision\": report_lr[\"weighted avg\"][\"precision\"],\n",
    "        \"Recall\": report_lr[\"weighted avg\"][\"recall\"]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"Accuracy\": report_xgb[\"accuracy\"],\n",
    "        \"F1_score\": report_xgb[\"weighted avg\"][\"f1-score\"],\n",
    "        \"Precision\": report_xgb[\"weighted avg\"][\"precision\"],\n",
    "        \"Recall\": report_xgb[\"weighted avg\"][\"recall\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convertir a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_summary).T\n",
    "\n",
    "# Gráfico\n",
    "ax = metrics_df.plot(kind=\"bar\", figsize=(12, 7), edgecolor='black')\n",
    "plt.title(\"📊 Comparación de Modelos de Clasificación\")\n",
    "plt.ylabel(\"Puntaje\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.legend(loc=\"lower right\", title=\"Métrica\")\n",
    "\n",
    "# Añadir etiquetas a cada barra\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.2f', label_type='edge', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4046cf5-05a5-45f6-8281-c609ea9f5889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo guardado como 'modelo_lightgbm_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define el nombre del archivo\n",
    "filename = \"modelo_lightgbm_final.pkl\"\n",
    "\n",
    "# Guarda el modelo entrenado\n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(model_lgbm, f)\n",
    "\n",
    "print(f\"✅ Modelo guardado como '{filename}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
